{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "for dependency in (\"brown\", \"names\", \"wordnet\", \"averaged_perceptron_tagger\", \"universal_tagset\"):\n",
    "    nltk.download(dependency)\n",
    "import re\n",
    "import string\n",
    "from sklearn.base import TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (11,7), fontsize=9, ylabel='True label', xlabel='Predicted label'):\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True , fmt=\"d\")\n",
    "        \n",
    "    except ValueError:\n",
    "        \n",
    "        raise ValueError(\"Confusion matrix values must be integers\")\n",
    "        \n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, X_test, y_test, target_names=None):\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    scores_test = cross_val_score(model, X_test, y_test, cv=5, scoring='accuracy')\n",
    "    \n",
    "    print(\"Accuracy train: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "    print(\"Accuracy test: %0.2f (+/- %0.2f)\" % (scores_test.mean(), scores_test.std()))\n",
    "    \n",
    "    print(\"Test classification report: \")\n",
    "    if target_names is None:\n",
    "        target_names = model.classes_\n",
    "    print(classification_report(y_test, model.predict(X_test), target_names=target_names))\n",
    "    print(\"Test confusion matrix: \")\n",
    "    print_confusion_matrix(confusion_matrix(y_test, model.predict(X_test)), class_names=target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dataset consisting of IMDB reviews with their subsequent sentiment classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at first 10 rows of the dataset\n",
    "imdb_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of positive and negative sentiments to ensure there is no presence of class imbalance.\n",
    "imdb_data.groupby(['sentiment']).agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=imdb_data.sentiment.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data using Spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "#nlp = spacy.load(\"en\", disable=['parser', 'tagger', 'ner'])\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data.review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPLIST = set(stopwords.words('english') + [\"n't\", \"'s\", \"'m\", \"ca\"] + list(ENGLISH_STOP_WORDS) + list(STOP_WORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor(TransformerMixin):\n",
    "    def __init__(self, text_attribute):\n",
    "        self.text_attribute = text_attribute\n",
    "        \n",
    "    def transform(self, X, *_):\n",
    "        X_copy = X.copy()\n",
    "        X_copy[self.text_attribute] = X_copy[self.text_attribute].apply(self._preprocess_text)\n",
    "        return X_copy\n",
    "    \n",
    "    def _preprocess_part(self, part):\n",
    "        return part.apply(self._preprocess_text)\n",
    "\n",
    "    def _preprocess_text(self, text):\n",
    "        normalized_text = self._normalize(text)\n",
    "        doc = nlp(normalized_text)\n",
    "        removed_punct = self._remove_punct(doc)\n",
    "        removed_stop_words = self._remove_stop_words(removed_punct)\n",
    "        removed_non_alpha = self._remove_non_alpha(removed_stop_words)\n",
    "        return self._lemmatize(removed_non_alpha)\n",
    "    \n",
    "    def _normalize(self, text):\n",
    "        try:\n",
    "            return ' '.join(normalise(text, variety=self.variety, user_abbrevs=self.user_abbrevs, verbose=False))\n",
    "        except:\n",
    "            return text\n",
    "\n",
    "    def _remove_punct(self, doc):\n",
    "        return [t for t in doc if t.text not in string.punctuation]\n",
    "\n",
    "    def _remove_stop_words(self, doc):\n",
    "        #return [t for t in doc if not t.is_stop]\n",
    "        return [t for t in doc if t.text not in STOPLIST]\n",
    "    \n",
    "    def _remove_non_alpha(self, doc):\n",
    "        filtered = []\n",
    "        for t in doc:\n",
    "            lexeme = nlp.vocab[str(t)]\n",
    "            if lexeme.is_stop == False and lexeme.is_alpha == True and lexeme.is_oov == False:\n",
    "                filtered.append(t)\n",
    "        return filtered\n",
    "\n",
    "    def _lemmatize(self, text):\n",
    "        lemma_list = []\n",
    "        for t in text:\n",
    "            if(len(t.text)>1):\n",
    "                lemma_list.append(t.lower_)\n",
    "        return ' '.join([t.lemma_ for t in text])\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes almost an hour to run\n",
    "text_preprocessor = TextPreprocessor(text_attribute='review')\n",
    "imdb_preprocessed = text_preprocessor.transform(imdb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all text under \"review\" to lowercase\n",
    "imdb_preprocessed.review = imdb_preprocessed.review.str.lower()\n",
    "\n",
    "# Taking a glance at the preprocessed text of the first review\n",
    "imdb_preprocessed.review[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset into 70:30 train/test parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(imdb_preprocessed, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining TF-IDF vectors on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer = \"word\")\n",
    "\n",
    "X_tfidf_train = tfidf.fit_transform(train['review'])\n",
    "X_tfidf_test = tfidf.transform(test['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['sentiment']\n",
    "y_test = test['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining predictions using Naive Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "nb_clf = MultinomialNB().fit(X_tfidf_train, y_train)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "\n",
    "nb_y_pred = nb_clf.predict(X_tfidf_test)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_cm = confusion_matrix(y_test, nb_y_pred, labels = [\"negative\", \"positive\"])\n",
    "print(nb_cm)\n",
    "print(\"\\nAccuracy : \", round(accuracy_score(y_test, nb_y_pred)*100,2),\"%\\n\")\n",
    "print(classification_report(y_test, nb_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_model(nb_clf, X_tfidf_train, y_train, X_tfidf_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining predictions using Random Forest model (bagging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# As you increase the max_depth, accuracy increases. Try playing around with the hyperparameter values\n",
    "rf_clf = RandomForestClassifier(max_depth=10, random_state=0).fit(X_tfidf_train, y_train)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "rf_y_pred = rf_clf.predict(X_tfidf_test)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cm = confusion_matrix(y_test, rf_y_pred, labels = [\"negative\", \"positive\"])\n",
    "print(rf_cm)\n",
    "print(\"\\nAccuracy : \", round(accuracy_score(y_test, rf_y_pred)*100,2),\"%\\n\")\n",
    "print(classification_report(y_test, rf_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(rf_clf, X_tfidf_train, y_train, X_tfidf_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining predictions using Gradient Boosting model (boosting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, \n",
    "                                    max_depth=1, random_state=0).fit(X_tfidf_train, y_train)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "gb_y_pred = gb_clf.predict(X_tfidf_test)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_cm = confusion_matrix(y_test, gb_y_pred, labels = [\"negative\", \"positive\"])\n",
    "print(gb_cm)\n",
    "print(\"\\nAccuracy : \", round(accuracy_score(y_test, gb_y_pred)*100,2),\"%\\n\")\n",
    "print(classification_report(y_test, gb_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(gb_clf, X_tfidf_train, y_train, X_tfidf_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
